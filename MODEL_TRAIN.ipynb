{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTIL8j55Dewp",
        "outputId": "ff593d5d-532c-4961-9afe-b082768a3af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing ./phenoAI-0.1-py3-none-any.whl\n",
            "Collecting opencv-python (from phenoAI==0.1)\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tensorflow in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from phenoAI==0.1) (2.18.0)\n",
            "Collecting keras (from phenoAI==0.1)\n",
            "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tqdm in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from phenoAI==0.1) (4.66.5)\n",
            "Requirement already satisfied: segmentation-models in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from phenoAI==0.1) (1.0.1)\n",
            "Collecting xlsxwriter (from phenoAI==0.1)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting albumentations (from phenoAI==0.1)\n",
            "  Downloading albumentations-1.4.20-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting imgaug (from phenoAI==0.1)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations->phenoAI==0.1) (1.26.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations->phenoAI==0.1) (1.11.4)\n",
            "Requirement already satisfied: PyYAML in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations->phenoAI==0.1) (6.0.2)\n",
            "Collecting pydantic>=2.7.0 (from albumentations->phenoAI==0.1)\n",
            "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "Collecting albucore==0.0.19 (from albumentations->phenoAI==0.1)\n",
            "  Downloading albucore-0.0.19-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting eval-type-backport (from albumentations->phenoAI==0.1)\n",
            "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opencv-python-headless>=4.9.0.80 (from albumentations->phenoAI==0.1)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
            "Collecting typing-extensions>=4.9.0 (from albumentations->phenoAI==0.1)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting stringzilla>=3.10.4 (from albucore==0.0.19->albumentations->phenoAI==0.1)\n",
            "  Downloading stringzilla-3.10.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (79 kB)\n",
            "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from imgaug->phenoAI==0.1) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from imgaug->phenoAI==0.1) (10.1.0)\n",
            "Requirement already satisfied: matplotlib in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from imgaug->phenoAI==0.1) (3.8.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from imgaug->phenoAI==0.1) (0.24.0)\n",
            "Requirement already satisfied: imageio in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from imgaug->phenoAI==0.1) (2.36.0)\n",
            "Collecting Shapely (from imgaug->phenoAI==0.1)\n",
            "  Downloading shapely-2.0.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: absl-py in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras->phenoAI==0.1) (2.1.0)\n",
            "Requirement already satisfied: rich in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras->phenoAI==0.1) (13.9.3)\n",
            "Requirement already satisfied: namex in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras->phenoAI==0.1) (0.0.8)\n",
            "Requirement already satisfied: h5py in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras->phenoAI==0.1) (3.12.1)\n",
            "Requirement already satisfied: optree in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras->phenoAI==0.1) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras->phenoAI==0.1) (0.4.1)\n",
            "Requirement already satisfied: packaging in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras->phenoAI==0.1) (23.2)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from segmentation-models->phenoAI==0.1) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from segmentation-models->phenoAI==0.1) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from segmentation-models->phenoAI==0.1) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (5.28.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (69.0.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (1.67.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow->phenoAI==0.1) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->phenoAI==0.1) (0.37.0)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.0->albumentations->phenoAI==0.1)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic>=2.7.0->albumentations->phenoAI==0.1)\n",
            "  Downloading pydantic_core-2.23.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow->phenoAI==0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow->phenoAI==0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow->phenoAI==0.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow->phenoAI==0.1) (2023.11.17)\n",
            "Requirement already satisfied: networkx>=2.8 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image>=0.14.2->imgaug->phenoAI==0.1) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image>=0.14.2->imgaug->phenoAI==0.1) (2024.8.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image>=0.14.2->imgaug->phenoAI==0.1) (0.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow->phenoAI==0.1) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow->phenoAI==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow->phenoAI==0.1) (3.0.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug->phenoAI==0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug->phenoAI==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug->phenoAI==0.1) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug->phenoAI==0.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug->phenoAI==0.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug->phenoAI==0.1) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug->phenoAI==0.1) (6.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras->phenoAI==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras->phenoAI==0.1) (2.17.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->imgaug->phenoAI==0.1) (3.17.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow->phenoAI==0.1) (7.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras->phenoAI==0.1) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->phenoAI==0.1) (2.1.5)\n",
            "Downloading albumentations-1.4.20-py3-none-any.whl (225 kB)\n",
            "Downloading albucore-0.0.19-py3-none-any.whl (11 kB)\n",
            "Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "Downloading pydantic_core-2.23.4-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading shapely-2.0.6-cp39-cp39-macosx_11_0_arm64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading stringzilla-3.10.5-cp39-cp39-macosx_11_0_arm64.whl (79 kB)\n",
            "Installing collected packages: stringzilla, xlsxwriter, typing-extensions, Shapely, opencv-python-headless, opencv-python, eval-type-backport, annotated-types, pydantic-core, albucore, pydantic, keras, imgaug, albumentations, phenoAI\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "Successfully installed Shapely-2.0.6 albucore-0.0.19 albumentations-1.4.20 annotated-types-0.7.0 eval-type-backport-0.2.0 imgaug-0.4.0 keras-3.6.0 opencv-python-4.10.0.84 opencv-python-headless-4.10.0.84 phenoAI-0.1 pydantic-2.9.2 pydantic-core-2.23.4 stringzilla-3.10.5 typing-extensions-4.12.2 xlsxwriter-3.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install phenoAI-0.1-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4jbcCBu6Eh4s",
        "outputId": "7c08b0fd-655a-4506-fd90-6106380c5aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in /Users/ishan/Library/Python/3.9/lib/python/site-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (5.28.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (69.0.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.67.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.26.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: rich in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (7.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras in /Users/ishan/Library/Python/3.9/lib/python/site-packages (3.6.0)\n",
            "Requirement already satisfied: absl-py in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (2.1.0)\n",
            "Requirement already satisfied: numpy in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (1.26.2)\n",
            "Requirement already satisfied: rich in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (13.9.3)\n",
            "Requirement already satisfied: namex in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: efficientnet in /Users/ishan/Library/Python/3.9/lib/python/site-packages (1.0.0)\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from efficientnet) (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.26.2)\n",
            "Requirement already satisfied: h5py in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.12.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image->efficientnet) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.8 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image->efficientnet) (3.2.1)\n",
            "Requirement already satisfied: pillow>=9.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image->efficientnet) (10.1.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image->efficientnet) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image->efficientnet) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image->efficientnet) (23.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from scikit-image->efficientnet) (0.4)\n",
            "Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: efficientnet\n",
            "  Attempting uninstall: efficientnet\n",
            "    Found existing installation: efficientnet 1.0.0\n",
            "    Uninstalling efficientnet-1.0.0:\n",
            "      Successfully uninstalled efficientnet-1.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "segmentation-models 1.0.1 requires efficientnet==1.0.0, but you have efficientnet 1.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed efficientnet-1.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade tensorflow\n",
        "%pip install --upgrade keras\n",
        "%pip install --upgrade efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asv9qXAoD1xf",
        "outputId": "c45e6614-8a39-419b-882f-4a7c11b27086"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ishan/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n",
            "Documentation:\n",
            "This Package contains three module-\n",
            "\n",
            "1. formatFilesName(dataset_path,date_format,start_index): To rename images file names that help in extracting Date from file name. File formating is mandatory before analysis.\n",
            "Here, dataset_path: location of image data and labels,\n",
            "date_format: format of the date which is written in all files name.It should contains 'yyyy', 'dd' and 'mm'. For examples: 'yyyy-mm-dd' for (2019-05-11), 'mmddyyyy' for(04221999) etc.\n",
            "index: It is the index in filenames from where date_format starts/ends. It must be same for all files. Consider name of the file without its extesion. Date index must be >= 1 (from left to right) or <= -1 (from right to left). \n",
            "For example suppose file names are like-  'Screenshot_20221204-15:22:59-586_com.google.jpg', here, date_formate is 'yyyymmdd'(20221204) and index is 12(12th position from start in the file name). For 'assgrhekjnigen_04-11-2021_WA.png', date_format is 'mm-dd-yyyy'(04-11-2021) and index is -4 (4th position from back in the file name, not considering .png as part of file name). Choose index(from start or end) according to pattern of filenames, such that this index must be same for all files names.\n",
            "\n",
            "2.getPhenoModel(dataset_path): To make phenological Model by training through Image Dataset.\n",
            "dataset_path: dataset location(Containing images and labels).\n",
            "it has below functions:\n",
            "saveModel(path_location): Where phenological Model to be saved. You can provide folder location(model will be saved by default name in that folder) or folder location along with model name in zip format, for example- 'C:/your_model_name.zip'\n",
            "returnModel() : return phenological model object, that can be used further during analysis.\n",
            "\n",
            "3. buildPhenoAI(model,dataset_path,class_name): To make analysis object. It provides phenological parameters, chronological coefficients, plots etc.\n",
            "Here, model: it can be model zip file location or phenological model object obtained by getPhenoModel module\n",
            "dataset_path: Images location\n",
            "class_name: name of tree category on which you want to analyse. Name should be matching with one of the names used while labelling the dataset\n",
            "This module object associates below functions:\n",
            "showROIs(): shows images with ROIs selected\n",
            "saveROIsImage(path_location): save this ROIs Image in the provided path_location.\n",
            "setInitialParameters(min, max, slope1, SoS, slope2 , EoS): set initial parameters of plotting function for all GCC,BCC,RCC\n",
            "setInitialGCCParameters(min, max, slope1, SoS, slope2 , EoS): same used for individual GCC\n",
            "setInitialBCCParameters(min, max, slope1, SoS, slope2 , EoS): for BCC\n",
            "setInitialECCParameters(min, max, slope1, SoS, slope2 , EoS): for RCC\n",
            "extractGCCParameters(): Gives 6 phenological parameters\n",
            "extractBCCParameters(): for BCC\n",
            "extractRCCParameters(): for RCC\n",
            "plotGCC(): plots GCC verses Day of Year(DoY) graph\n",
            "plotGCC(),plotRCC(): for BCC and RCC\n",
            "saveGCCPlot(path_location):save GCC vs DoY plot images in given location\n",
            "saveBCCPlot(path_location),saveRCCPlot(path_location) for BCC and RCC\n",
            "saveCCsTimeSeries(path_location): save all record GCC,BCC,RCC, 6 parameters in Excel file in the given location\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import phenoAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1oNLRitOixl",
        "outputId": "ca4d55d3-9fb4-42b6-9884-711588688f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Build_Pheno_AI', 'Get_Pheno_Model', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'buildPhenoAI', 'formatFilesName', 'getPhenoModel', 'set_date_formate']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(dir(phenoAI)) #Removed the extra indent before print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M607ovZLPh7k",
        "outputId": "30be58ec-1899-4685-dfc5-1d883380fd78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help for Build_Pheno_AI:\n",
            "Help on package phenoAI.Build_Pheno_AI in phenoAI:\n",
            "\n",
            "NAME\n",
            "    phenoAI.Build_Pheno_AI\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    CC_Parameters\n",
            "    ROIs\n",
            "    calculate_CCs\n",
            "    extract_model\n",
            "    image_fps\n",
            "    main\n",
            "    save_CCs_TimeSeries\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/phenoAI/Build_Pheno_AI/__init__.py\n",
            "\n",
            "\n",
            "--------------------\n",
            "Help for Get_Pheno_Model:\n",
            "Help on package phenoAI.Get_Pheno_Model in phenoAI:\n",
            "\n",
            "NAME\n",
            "    phenoAI.Get_Pheno_Model\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    Augmentation\n",
            "    Json_to_mask\n",
            "    data_preparation\n",
            "    main\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/phenoAI/Get_Pheno_Model/__init__.py\n",
            "\n",
            "\n",
            "--------------------\n",
            "Help for buildPhenoAI:\n",
            "Help on class buildPhenoAI in module phenoAI.Build_Pheno_AI.main:\n",
            "\n",
            "class buildPhenoAI(builtins.object)\n",
            " |  buildPhenoAI(model, dataset_path, class_name, required_rois=5)\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, model, dataset_path, class_name, required_rois=5)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  extractBCCParameters(self)\n",
            " |  \n",
            " |  extractGCCParameters(self)\n",
            " |  \n",
            " |  extractRCCParameters(self)\n",
            " |  \n",
            " |  getBCC(self)\n",
            " |  \n",
            " |  getDoY(self)\n",
            " |  \n",
            " |  getGCC(self)\n",
            " |  \n",
            " |  getRCC(self)\n",
            " |  \n",
            " |  plotBCC(self)\n",
            " |  \n",
            " |  plotGCC(self)\n",
            " |  \n",
            " |  plotRCC(self)\n",
            " |  \n",
            " |  saveBCCPlot(self, path_location)\n",
            " |  \n",
            " |  saveCCsTimeSeries(self, path_location)\n",
            " |  \n",
            " |  saveGCCPlot(self, path_location)\n",
            " |  \n",
            " |  saveRCCPlot(self, path_location)\n",
            " |  \n",
            " |  saveROIsImage(self, path_location)\n",
            " |  \n",
            " |  setInitialBCCParameters(self, min, max, slope1, SoS, slope2, EoS)\n",
            " |  \n",
            " |  setInitialGCCParameters(self, min, max, slope1, SoS, slope2, EoS)\n",
            " |  \n",
            " |  setInitialParameters(self, min, max, slope1, SoS, slope2, EoS)\n",
            " |  \n",
            " |  setInitialRCCParameters(self, min, max, slope1, SoS, slope2, EoS)\n",
            " |  \n",
            " |  showROIs(self)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n",
            "--------------------\n",
            "Help for formatFilesName:\n",
            "Help on function formatFilesName in module phenoAI.set_date_formate.main:\n",
            "\n",
            "formatFilesName(dataset_path, date_format, index)\n",
            "\n",
            "--------------------\n",
            "Help for getPhenoModel:\n",
            "Help on class getPhenoModel in module phenoAI.Get_Pheno_Model.main:\n",
            "\n",
            "class getPhenoModel(builtins.object)\n",
            " |  getPhenoModel(dataset_path)\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, dataset_path)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  returnModel(self)\n",
            " |  \n",
            " |  saveModel(self, path_location)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n",
            "--------------------\n",
            "Help for set_date_formate:\n",
            "Help on package phenoAI.set_date_formate in phenoAI:\n",
            "\n",
            "NAME\n",
            "    phenoAI.set_date_formate\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    main\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/phenoAI/set_date_formate/__init__.py\n",
            "\n",
            "\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import phenoAI\n",
        "\n",
        "# List of functions you're interested in\n",
        "functions_to_check = ['Build_Pheno_AI', 'Get_Pheno_Model', 'buildPhenoAI', 'formatFilesName', 'getPhenoModel', 'set_date_formate']\n",
        "\n",
        "# Loop through the functions and print their help information\n",
        "for function_name in functions_to_check:\n",
        "    try:\n",
        "        print(f\"Help for {function_name}:\")\n",
        "        help(getattr(phenoAI, function_name))  # Get the function object using getattr\n",
        "        print(\"-\" * 20)  # Separator for better readability\n",
        "    except AttributeError:\n",
        "        print(f\"Function '{function_name}' not found in phenoAI module.\")\n",
        "        print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WPWVuAaHPMMy"
      },
      "outputs": [],
      "source": [
        "from phenoAI import Build_Pheno_AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tlJ-P4x7EGgu"
      },
      "outputs": [],
      "source": [
        "dataset_path=r'D:\\DAI PROJECT\\labelled'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "PTLsUc1OObv0",
        "outputId": "20fe846d-2ead-4c84-b247-553727ab121e"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'module' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-118041c19328>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpheno_model\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mBuild_Pheno_AI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_augmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ],
      "source": [
        "pheno_model =Build_Pheno_AI(dataset_path, epochs = 35,learning_rate = 0.001, batch_size = 16,is_augmentation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtGq0XxLOeUj",
        "outputId": "a62db8cb-2e6e-49da-e62c-ef088a238bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in /Users/ishan/Library/Python/3.9/lib/python/site-packages (2.18.0)\n",
            "Requirement already satisfied: opencv-python-headless in /Users/ishan/Library/Python/3.9/lib/python/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: albumentations in /Users/ishan/Library/Python/3.9/lib/python/site-packages (1.4.20)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (5.28.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (69.0.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.67.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.26.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: PyYAML in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore==0.0.19 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from albucore==0.0.19->albumentations) (3.10.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: rich in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (7.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/ishan/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow opencv-python-headless albumentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mrvrhl9aYEVs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rjaf1YaxYIRR"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "DATASET_PATH = r\"/content/sample\"  # Update your dataset path here\n",
        "IMG_HEIGHT, IMG_WIDTH = 256, 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 25\n",
        "\n",
        "# Functions for loading dataset and processing annotations\n",
        "def load_classes(dataset_path):\n",
        "    classes = set()\n",
        "    for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
        "        json_files = glob.glob(os.path.join(dirpath, \"*.json\"))\n",
        "        for json_file in json_files:\n",
        "            with open(json_file) as f:\n",
        "                data = json.load(f)\n",
        "                for shape in data['shapes']:\n",
        "                    classes.add(shape['label'])\n",
        "    return list(classes)\n",
        "\n",
        "def convert_annotation_json_to_mask(path_to_annotation_json):\n",
        "    with open(path_to_annotation_json) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    h = data['imageHeight']\n",
        "    w = data['imageWidth']\n",
        "    mask = np.zeros((h, w), dtype=np.uint8)\n",
        "\n",
        "    for annot in data['shapes']:\n",
        "        points = np.array(annot['points'], dtype=np.int32)\n",
        "        cv2.fillPoly(mask, [points], color=255)\n",
        "\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a9ytyMq3YKv8"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, dataset_path, augmentation=None):\n",
        "        self.images_fps = []\n",
        "        self.mask_fps = []\n",
        "        self.augmentation = augmentation\n",
        "        self.classes = load_classes(dataset_path)\n",
        "\n",
        "        for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
        "            img_src = glob.glob(os.path.join(dirpath, '*.JPEG')) + glob.glob(os.path.join(dirpath, '*.JPG'))\n",
        "            json_files = glob.glob(os.path.join(dirpath, '*.json'))\n",
        "\n",
        "            for img_file in img_src:\n",
        "                self.images_fps.append(img_file)\n",
        "\n",
        "            for json_file in json_files:\n",
        "                mask = convert_annotation_json_to_mask(json_file)\n",
        "                mask_file = img_file.replace('.JPEG', '_mask.png').replace('.JPG', '_mask.png')\n",
        "                cv2.imwrite(mask_file, mask)\n",
        "                self.mask_fps.append(mask_file)\n",
        "\n",
        "        assert len(self.images_fps) == len(self.mask_fps), \"Mismatch between images and masks.\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(self.images_fps[index])\n",
        "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "        mask = cv2.imread(self.mask_fps[index], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "        mask = mask / 255.0  # Normalize mask to [0, 1]\n",
        "\n",
        "        if self.augmentation:\n",
        "            augmented = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_fps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ue-f3tNgYODt"
      },
      "outputs": [],
      "source": [
        "def get_augmentation():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf6i8_5TYUxZ",
        "outputId": "2d19cc55-4b2b-4b10-9736-dc4443dda598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80s/step - accuracy: 0.5988 - loss: 0.6923 - val_accuracy: 0.7320 - val_loss: 0.6874\n",
            "Epoch 2/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.7302 - loss: 0.6782 - val_accuracy: 0.7320 - val_loss: 0.6821\n",
            "Epoch 3/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7319 - loss: 0.6172 - val_accuracy: 0.7320 - val_loss: 0.6779\n",
            "Epoch 4/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7320 - loss: 0.4647 - val_accuracy: 0.7320 - val_loss: 0.6747\n",
            "Epoch 5/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.7320 - loss: 0.3926 - val_accuracy: 0.7320 - val_loss: 0.6758\n",
            "Epoch 6/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.7320 - loss: 0.4336 - val_accuracy: 0.7320 - val_loss: 0.6770\n",
            "Epoch 7/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7320 - loss: 0.4249 - val_accuracy: 0.7320 - val_loss: 0.6748\n",
            "Epoch 8/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.7320 - loss: 0.3741 - val_accuracy: 0.7320 - val_loss: 0.6662\n",
            "Epoch 9/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7320 - loss: 0.3564 - val_accuracy: 0.7320 - val_loss: 0.6524\n",
            "Epoch 10/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.7320 - loss: 0.3483 - val_accuracy: 0.7320 - val_loss: 0.6368\n",
            "Epoch 11/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7320 - loss: 0.3442 - val_accuracy: 0.7320 - val_loss: 0.6201\n",
            "Epoch 12/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.7322 - loss: 0.3420 - val_accuracy: 0.7320 - val_loss: 0.5950\n",
            "Epoch 13/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7324 - loss: 0.3312 - val_accuracy: 0.7320 - val_loss: 0.5800\n",
            "Epoch 14/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7325 - loss: 0.3197 - val_accuracy: 0.7321 - val_loss: 0.5915\n",
            "Epoch 15/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7325 - loss: 0.3183 - val_accuracy: 0.7324 - val_loss: 0.6115\n",
            "Epoch 16/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 0.7326 - loss: 0.3157 - val_accuracy: 0.7326 - val_loss: 0.6223\n",
            "Epoch 17/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7326 - loss: 0.3101 - val_accuracy: 0.7329 - val_loss: 0.6254\n",
            "Epoch 18/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 0.7327 - loss: 0.3061 - val_accuracy: 0.7330 - val_loss: 0.6179\n",
            "Epoch 19/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7328 - loss: 0.3038 - val_accuracy: 0.7331 - val_loss: 0.6112\n",
            "Epoch 20/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7327 - loss: 0.3023 - val_accuracy: 0.7334 - val_loss: 0.6217\n",
            "Epoch 21/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.7330 - loss: 0.2969 - val_accuracy: 0.7336 - val_loss: 0.6478\n",
            "Epoch 22/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7331 - loss: 0.2985 - val_accuracy: 0.7338 - val_loss: 0.6927\n",
            "Epoch 23/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.8887 - loss: 0.2984 - val_accuracy: 0.7339 - val_loss: 0.7419\n",
            "Epoch 24/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.8999 - loss: 0.2935 - val_accuracy: 0.7341 - val_loss: 0.7924\n",
            "Epoch 25/25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9062 - loss: 0.2909 - val_accuracy: 0.7346 - val_loss: 0.8286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'efficientnet_model.h5'\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "\n",
        "def create_model(num_classes):\n",
        "    base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "    base_model.trainable = True\n",
        "\n",
        "    inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "    x = base_model(inputs, training=True)\n",
        "\n",
        "    # Upsample to original image size using Conv2DTranspose\n",
        "    x = layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)  # 8x8 -> 16x16\n",
        "    x = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)  # 16x16 -> 32x32\n",
        "    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)  # 32x32 -> 64x64\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)    # 64x64 -> 128x128\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)    # 128x128 -> 256x256\n",
        "\n",
        "    # Final output layer\n",
        "    outputs = layers.Conv2D(num_classes, (1, 1), activation='softmax')(x)  # Output shape (256, 256, num_classes)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main script\n",
        "augmentation = get_augmentation()\n",
        "dataset = Dataset(DATASET_PATH, augmentation)\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "    dataset.images_fps, dataset.mask_fps, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = Dataset(DATASET_PATH, augmentation)\n",
        "val_dataset = Dataset(DATASET_PATH)\n",
        "\n",
        "# Create TensorFlow Datasets\n",
        "def dataset_generator(dataset):\n",
        "    for i in range(len(dataset)):\n",
        "        image, mask = dataset[i]\n",
        "        yield image, mask  # mask should be of shape (IMG_HEIGHT, IMG_WIDTH)\n",
        "\n",
        "train_tf_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: dataset_generator(train_dataset),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH), dtype=tf.int32)  # Class indices\n",
        "    )\n",
        ")\n",
        "\n",
        "val_tf_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: dataset_generator(val_dataset),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH), dtype=tf.int32)  # Class indices\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create and train the model\n",
        "model = create_model(len(dataset.classes))\n",
        "\n",
        "# Use TensorFlow Datasets for training\n",
        "model.fit(train_tf_dataset.batch(BATCH_SIZE),\n",
        "          validation_data=val_tf_dataset.batch(BATCH_SIZE),\n",
        "          epochs=EPOCHS)\n",
        "\n",
        "# Save the model\n",
        "model.save('efficientnet_model.h5')\n",
        "print(\"Model saved as 'efficientnet_model.h5'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nmmGdUBm2Sv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
